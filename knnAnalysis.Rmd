---
title: "knn Analysis"
author: "Kay, Belen, Amanda"
date: "4/14/2021"
output:
  html_document:
    toc: TRUE
    theme: journal
    toc_float: TRUE
editor_options:
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load-packages, include=FALSE}
install.packages("naniar")
library(dplyr)
library(magrittr)
library(knitr)
library(naniar)
library(ggplot2)
```

# Data set 1: Outcomes of cancer patients
This first data set contains the overall outcomes of cancer patients, along with many other data points about the patient's health. The question we are hoping to answer is as follows: after cleaning data and removing any data points that create noise, can we create a KNN model that uses some health factors to predict whether or not the patient had a positive outcome at a rate better than the baseline?

## Find out which columns have many missing values so that they can be discarded
```{r, message=FALSE, echo = FALSE, warning=FALSE}

cancer_data = read.csv("hcc.csv")
cancer_data[cancer_data=="?"] <- NA

gg_miss_var(cancer_data)
```

We removed the columns with many missing values and columns that affect accuracy. After that, we found that the base level for identifying if a patient would survive or not was 60.4%.
```{r, message=FALSE, echo = FALSE, warning=FALSE}
cancer_data_2 <- cancer_data[,colSums(is.na(cancer_data))<3]

cancer_data_2 <- cancer_data_2[complete.cases(cancer_data_2), ]


# The split between is 96 survivors of cancer and 63 victims of cancer.

split <- table(cancer_data_2$Class)[2] / sum(table(cancer_data_2$Class))

# The base rate is 60.4 % for identifying if a patient would survive or not.

cancer_data_2 <- sapply( cancer_data_2, as.numeric )

# Scale the data
cancer_data_2 <- as.data.frame(cancer_data_2)
cancer_data_2[, -11] <- lapply(cancer_data_2[, -11],function(x) scale(x))

# Find correlations in the data 

stat_correlations <- cor(cancer_data_2)
# View(stat_correlations)

# These variables highly affected accuracy, as we found by plotting what the accuracy plot looks like without each column
cancer_data_2 <- cancer_data_2[, -c(5, 6, 9)]
```

## Plot k vs. accuracy to see how many neighbors to use
Based on the plot that was created, 3 was the best number of neighbors for a higher accuracy level.
```{r, message=FALSE, echo = FALSE, warning=FALSE}
set.seed(1982)
cancer_data_train_rows = sample(1:nrow(cancer_data_2),
                              round(0.8 * nrow(cancer_data_2), 0),
                              replace = FALSE)

# Check to make sure we have 80% of the rows
percent_or_rows = length(cancer_data_train_rows) / nrow(cancer_data_2)

# Rows used in training set
cancer_data_train = cancer_data_2[cancer_data_train_rows, ]

# Rows not used in training set, aka the test set
cancer_data_test = cancer_data_2[-cancer_data_train_rows, ]

# Check the number of rows in each set.
# nrow(cancer_data_train)
# nrow(cancer_data_test)

# Figure out which K to use

# install.packages("class") 
library(class)

chooseK = function(k, train_set, val_set, train_class, val_class){
  set.seed(1)
  class_knn = knn(train = train_set,
                  test = val_set,
                  cl = train_class,
                  k = k,
                  use.all = TRUE)
  conf_mat = table(class_knn, val_class)

  test <- conf_mat

  # Accuracy = (TP + TN) / (TP + TN + FP + FN)
  accu = sum(conf_mat[row(conf_mat) == col(conf_mat)]) / sum(conf_mat)

  cbind(k = k, accuracy = accu)
}

knn_diff_k_cancer = sapply(seq(1, 21, by = 2),  #<- set k to be odd number from 1 to 21
                         function(x) chooseK(x,
                                             train_set =
                                               cancer_data_train[, -c( 8)],
                                             val_set = cancer_data_test[, -c(8)],
                                             train_class = cancer_data_train[, 8],
                                             val_class = cancer_data_test[, 8]))


knn_diff_k_cancer = tibble(k = knn_diff_k_cancer[1,],
                             accuracy = knn_diff_k_cancer[2,])

ggplot(knn_diff_k_cancer,
       aes(x = k, y = accuracy)) +
  geom_line(color = "orange", size = 1.5) +
  geom_point(size = 3)
```

## Run KNN analysis with 3 nearest neighbors and analyze the accuracy of the model
```{r, message=FALSE, echo = FALSE, warning=FALSE}

# Try 3 nearest neighbors

cancer_15NN <-  knn(train = cancer_data_train[, -8],
               test = cancer_data_test[, -8],
               cl = cancer_data_train[, 8],
               k = 3,
               use.all = TRUE,
               prob = TRUE)

str(cancer_15NN)
View(cancer_15NN)

kNN_res = table(cancer_15NN,
                cancer_data_test$Class)
View(kNN_res)

conf_matrix_initial <- kNN_res

# conf_matrix_initial

library(caret)
install.packages("e1071")
library(e1071)
```

Originally, the baseline accuracy was around 60%;  accuracy is now up to 71.8%. The sensitivity is 75%, while the specificity is 67%. This means that the false positive rate is 33%, which is a bit high but certainly not terrible. The F1 value is 76.9%. All of these statistics are fairly good, especially when you compare the baseline to the prediction model.

The kappa value is 0.410, which is relatively weak for a kappa value.
```{r, message=FALSE, echo = FALSE, warning=FALSE}
conf_matrix <- confusionMatrix(as.factor(cancer_15NN), as.factor(cancer_data_test$Class), positive = "1", dnn=c("Prediction", "Actual"), mode = "sens_spec")

conf_matrix
conf_matrix$overall["Accuracy"]
conf_matrix$overall["Kappa"]
conf_matrix$byClass["Sensitivity"]
conf_matrix$byClass["Specificity"]
conf_matrix$byClass["F1"]



# install.packages("MLmetrics")
library(MLmetrics)

LogLoss(as.numeric(attributes(cancer_15NN)$prob), as.numeric(cancer_data_test$Class))
# #We want this number to be rather close to 0, so this is a pretty terrible result. 
# 


cancer_data_test$result = cancer_15NN
F1_Score(as.numeric(cancer_data_test$result),as.numeric(cancer_data_test$Class))
 

cancer_15NN$prob
cancer15<-as.data.frame(cancer_15NN.prob)
# ?MLmetrics
attr(cancer_15NN, prob)

# attributes(cancer_15NN)$prob


```

# Data set 2: Reviews of coffee shops
